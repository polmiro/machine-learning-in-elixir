# Chapter 1: Make machines that learn

```elixir
Mix.install([
  {:axon, "~> 0.5"},
  {:nx, "~> 0.5"},
  {:explorer, "~> 0.5"},
  {:kino, "~> 0.8"}
])
```

## Set up Dataframe

```elixir
require Explorer.DataFrame, as: DF
require Explorer.Query
```

## Load Dataset

```elixir
iris = Explorer.Datasets.iris()
```

## Normalization (standardization)

```elixir
cols = ~w(
  sepal_length
  sepal_width
  petal_length 
  petal_width
)

normalized_iris =
  DF.mutate(
    iris,
    for col <- across(^cols) do
      {col.name, (col - mean(col)) / variance(col)}
    end
  )
```

## Shuffle (simulate real data)

```elixir
shuffled_normalized_iris = DF.shuffle(normalized_iris)
```

## Conversion to tensors

```elixir
feature_columns = ~w(
  sepal_length
  sepal_width
  petal_length 
  petal_width
)
label_column = "species"

x_all = Nx.stack(shuffled_normalized_iris[feature_columns], axis: 1)

y_all =
  shuffled_normalized_iris["species"]
  |> Explorer.Series.cast(:category)
  |> Nx.stack(axis: -1)
  |> Nx.equal(Nx.iota({1, 3}, axis: -1))
```

## Separate datasets

```elixir
x_train = x_all[0..119]
y_train = y_all[0..119]

x_test = x_all[120..149]
y_test = y_all[120..149]
```

## Multinominal Logistic Regression

### Build model

```elixir
model =
  Axon.input("iris_features")
  |> Axon.dense(3, activation: :softmax)
```

```elixir
Axon.Display.as_graph(model, Nx.template({1, 4}, :f32))
```

```elixir
data_stream = Stream.repeatedly(fn -> {x_train, y_train} end)
```

```elixir
trained_model_state =
  model
  |> Axon.Loop.trainer(:categorical_cross_entropy, :sgd)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(data_stream, %{}, iterations: 500, epochs: 10)
```

### Evaluate model

```elixir
data = [{x_test, y_test}]

model
|> Axon.Loop.evaluator()
|> Axon.Loop.metric(:accuracy)
|> Axon.Loop.run(data, trained_model_state)
```
